{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, re\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "count = dict()\n",
    "count_c = defaultdict(lambda: 0)\n",
    "for line in open('count_1edit.txt', 'r', encoding='utf8'):\n",
    "    wc, num = line.strip().split('\\t')\n",
    "    w, c = wc.split('|')\n",
    "    count[(w, c)] = int(num)\n",
    "    count_c[c] += int(num)\n",
    "Ncount = Counter(count.values())\n",
    "\n",
    "Nall = len(count.keys())\n",
    "N0 = 26*26*26*26+2*26*26*26+26*26 - Nall\n",
    "Nr = [ N0 if r == 0 else Ncount[r] for r in range(12) ]\n",
    "\n",
    "def smooth(count, r=10):\n",
    "    if count <= r:\n",
    "        return (count+1)*Nr[count+1] / Nr[count]\n",
    "    else:\n",
    "        return count\n",
    "\n",
    "def Pedit(w, c):\n",
    "    if (w, c) not in count and count_c[c] > 0:\n",
    "        return smooth(0) / count_c[c]\n",
    "    if count_c[c] > 0:\n",
    "        return smooth(count[(w, c)]) / count_c[c]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "# WORDS = Counter(open('big.txt').read().split())\n",
    "\n",
    "def Pw(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    states = [ ('', word, 0, Pw(word), 1) ]\n",
    "    for i in range(len(word)):\n",
    "        # print(i, states[:3])\n",
    "        STATES = [ s for state in states for s in next_states(state) ]\n",
    "        states = sorted(STATES, key=lambda x: x[2])\n",
    "\n",
    "        unique, new_states = set(), []\n",
    "        for state in states:\n",
    "            if state[0] + state[1] in unique: continue\n",
    "\n",
    "            unique.add(state[0] + state[1])\n",
    "            new_states.append(state)\n",
    "        states = new_states\n",
    "        states = sorted(states, key=lambda x: P(x[3], x[4]), reverse=True) [:500]# [:MAXBEAM]\n",
    "    return states[:10]\n",
    "\n",
    "def next_states(state):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    L, R, edit, prob, ped = state\n",
    "    R0, R1 = R[0], R[1:]\n",
    "    if edit == 2: return [( L + R0, R1, edit, prob, ped*0.8 )]\n",
    "    noedit    = [( L + R0, R1, edit, prob, ped*0.8 )]\n",
    "    delete    = [( L, R1, edit+1, Pw(L + R1), ped * Pedit(L[-1]+R0, L[-1]))]  if len(L) > 0 else []\n",
    "    insert    = [( L + R0 + c, R1, edit+1, Pw(L + R0 + c + R1), ped * Pedit(R0, R0 + c) ) for c in letters]\n",
    "    replace   = [( L + c, R1, edit+1, Pw(L + c + R1), ped * Pedit(R0, c) ) for c in letters]\n",
    "    transpose = [( L[:-1] + R0 + L[-1], R1, edit+1, Pw(L[:-1] + R0 + L[-1] + R1), ped * Pedit(L[-1]+R0, R0+L[-1]) )] if len(L) > 1 else []\n",
    "    return set(noedit + delete + replace + insert + transpose)\n",
    "\n",
    "'''Combining channel probability with word probability to score states'''\n",
    "def P(pw, pedit):\n",
    "    return pw*pedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"http://api.netspeak.org/netspeak3/search?query=%s\"\n",
    "\n",
    "class NetSpeak:\n",
    "    def __init__(self):\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "        self.page = None\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def __getPageContent(self, url):\n",
    "        return requests.get(url, headers=self.headers).text\n",
    "        # return self.opener.open(url).read()\n",
    "\n",
    "    def __rolling(self, url, maxfreq=None):\n",
    "        if maxfreq:\n",
    "            webdata = self.__getPageContent(url + \"&maxfreq=%s\" % maxfreq)\n",
    "        else:\n",
    "            webdata = self.__getPageContent(url)\n",
    "        if webdata:\n",
    "            # webdata = webdata.decode('utf-8')\n",
    "            results = [data.split('\\t') for data in webdata.splitlines()]\n",
    "            results = [(data[2], float(data[1])) for data in results]\n",
    "            lastFreq = int(results[-1][1])\n",
    "            if lastFreq != maxfreq:\n",
    "                return results + self.__rolling(url, lastFreq)\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def search(self, query):\n",
    "        if query in self.dictionary: return self.dictionary[query]\n",
    "        \n",
    "        queries = query.lower().split()\n",
    "        new_query = []\n",
    "        for token in queries:\n",
    "            if token.count('|') > 0:\n",
    "                new_query.append('[+{0}+]'.format('+'.join(token.split('|'))))\n",
    "            elif token == '*':\n",
    "                new_query.append('?')\n",
    "            else:\n",
    "                new_query.append(token)\n",
    "        new_query = '+'.join(new_query)\n",
    "        url = API_URL % (new_query.replace(' ', '+'))\n",
    "        self.dictionary[query] = self.__rolling(url)\n",
    "        return self.dictionary[query]\n",
    "    \n",
    "SE = NetSpeak() # singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "confuse_word = open('lab4.confusables.txt','r').readlines()\n",
    "Confuse = {}\n",
    "for line in confuse_word:\n",
    "    w ,c = line.split('\\t')\n",
    "    Confuse[w]=c.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigrams(tokens):\n",
    "    return [tokens[i:i+3] for i in range(len(tokens) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_where(tm):\n",
    "    trigrams = get_trigrams(tm)\n",
    "    tri_tmp = []\n",
    "    for index,tri in enumerate(trigrams):\n",
    "        #print(tri)\n",
    "        res = SE.search(' '.join(tri))\n",
    "        #print(res)\n",
    "        if res:\n",
    "            tri_tmp.append((index,res[0][1],tri))\n",
    "        else:\n",
    "            tri_tmp.append((index,0,tri))\n",
    "    #print(tri_tmp)\n",
    "    minn  = min(tri_tmp,key=lambda x:x[1])[2]\n",
    "    #print(minn)\n",
    "    for find_index in tri_tmp:\n",
    "        #print(find_index[2])\n",
    "        if find_index[2]==minn:\n",
    "            detect_sentence = find_index\n",
    "            \n",
    "    return detect_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_best(tm,start):\n",
    "    \n",
    "    best = (None, None, None, None, -math.inf)\n",
    "    #find_the_best = []\n",
    "    for i in range(start,start+3):\n",
    "        candidate = []\n",
    "        for corr in correction(tm[i]):\n",
    "            candidate.append(corr[0])\n",
    "        if tm[i] in Confuse.keys():\n",
    "            candidate.append(tm[i])\n",
    "        #print(candidate)\n",
    "        for cancan in candidate:\n",
    "            count = 1.0\n",
    "            combine = tm[:i] + [cancan] + tm[i+1:]\n",
    "            #print(math.log(Pw(cancan)))\n",
    "            trigrams = get_trigrams(combine)\n",
    "            \n",
    "            for tri in trigrams:\n",
    "                res = SE.search(' '.join(tri))\n",
    "                if res :\n",
    "                    count += math.log(res[0][1])\n",
    "                    count = (-math.log(Pw(cancan)))+count\n",
    "                else:0\n",
    "                \n",
    "                #print(res,count)\n",
    "                \n",
    "            best = (combine,tm[i],cancan,candidate,count) if count > best[-1] else best\n",
    "       \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割正確跟錯誤的資料集\n",
    "line = open('lab4.test.1.txt','r').readlines()\n",
    "Correct_sentence = []\n",
    "False_sentence = []\n",
    "for sentence in line:\n",
    "    tmp = sentence.split('\\t')\n",
    "    False_sentence.append(tmp[0].strip().lower())\n",
    "    Correct_sentence.append(tmp[1].strip().lower())\n",
    "test_Correct=Correct_sentence[:20]\n",
    "test_False = False_sentence[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:strang\n",
      "Candidates: ['strange', 'strong', 'staring', 'sprang', 'string', 'strings', 'spring', 'storing', 'strand', 'stand']\n",
      "Correction: strange\n",
      "i felt very strang -> i felt very strange\n",
      "hits = 1\n",
      "\n",
      "Error:brake\n",
      "Candidates: ['break', 'broken', 'broke', 'brake', 'bark', 'bracket', 'baker', 'breaks', 'braced', 'barked', 'brake']\n",
      "Correction: break\n",
      "at brake time -> at break time\n",
      "hits = 2\n",
      "\n",
      "Error:brack\n",
      "Candidates: ['black', 'back', 'branch', 'brick', 'bricks', 'breach', 'brisk', 'block', 'pack', 'backs']\n",
      "Correction: block\n",
      "when the brack was finished -> when the block was finished\n",
      "hits = 2\n",
      "\n",
      "Error:weanter\n",
      "Candidates: ['water', 'wanted', 'winter', 'wander', 'weaker', 'weather', 'walter', 'venter', 'waiter', 'decanter']\n",
      "Correction: winter\n",
      "in the weanter when it was snowing -> in the winter when it was snowing\n",
      "hits = 3\n",
      "\n",
      "Error:gost\n",
      "Candidates: ['just', 'most', 'ghost', 'got', 'cost', 'gross', 'must', 'get', 'coast', 'guest']\n",
      "Correction: ghost\n",
      "i thought it was a gost -> i thought it was a ghost\n",
      "hits = 4\n",
      "\n",
      "Error:expect\n",
      "Candidates: ['expect', 'expects', 'aspect', 'except', 'expert', 'export', 'extent', 'experts', 'expend', 'expel']\n",
      "Correction: except\n",
      "everything expect the houses -> everything except the houses\n",
      "hits = 5\n",
      "\n",
      "Error:steped\n",
      "Candidates: ['stepped', 'stooped', 'striped', 'stupid', 'stopped', 'shaped', 'steps', 'stephen', 'stated', 'stared']\n",
      "Correction: stepped\n",
      "when i first steped -> when i first stepped\n",
      "hits = 6\n",
      "\n",
      "Error:exclation\n",
      "Candidates: ['exclusion', 'excavation', 'exaltation', 'exultation', 'exudation', 'exception', 'expiation', 'elation', 'emulation', 'epilation']\n",
      "Correction: excavation\n",
      "i was on an exclation -> i was on an excavation\n",
      "hits = 6\n",
      "\n",
      "Error:noicey\n",
      "Candidates: ['notice', 'noticed', 'noise', 'nicely', 'notices', 'voice', 'novices', 'voices', 'novice', 'nice']\n",
      "Correction: notices\n",
      "i noicey that i was on this thing -> i notices that i was on this thing\n",
      "hits = 6\n",
      "\n",
      "Error:fance\n",
      "Candidates: ['france', 'face', 'fancy', 'fancies', 'faces', 'fancied', 'fence', 'fiancee', 'faced', 'force']\n",
      "Correction: fence\n",
      "through the fance -> through the fence\n",
      "hits = 7\n",
      "\n",
      "Error:kille\n",
      "Candidates: ['killed', 'kill', 'hill', 'till', 'killer', 'tilled', 'hills', 'kindle', 'kills', 'tiller']\n",
      "Correction: kill\n",
      "the hunters kille them -> the hunters kill them\n",
      "hits = 8\n",
      "\n",
      "Error:nerrow\n",
      "Candidates: ['narrow', 'marrow', 'morrow', 'narrows', 'sorrow', 'borrow', 'neuro', 'terror', 'negro', 'furrow']\n",
      "Correction: borrow\n",
      "they kill birds with their nerrow -> they kill birds with their borrow\n",
      "hits = 8\n",
      "\n",
      "Error:depe\n",
      "Candidates: ['deep', 'type', 'keep', 'depth', 'were', 'dip', 'weep', 'debt', 'pipe', 'kept']\n",
      "Correction: deep\n",
      "make a depe hole -> make a deep hole\n",
      "hits = 9\n",
      "\n",
      "Error:gardon\n",
      "Candidates: ['garden', 'gardens', 'gordon', 'pardon', 'carbon', 'cordon', 'garcon', 'pardons', 'carron', 'gallon']\n",
      "Correction: gardens\n",
      "to tidy up his gardon -> to tidy up his gardens\n",
      "hits = 9\n",
      "\n",
      "Error:belu\n",
      "Candidates: ['below', 'blue', 'bell', 'blew', 'ball', 'bill', 'begun', 'be', 'blur', 'well']\n",
      "Correction: blew\n",
      "the wind belu the leaves -> the wind blew the leaves\n",
      "hits = 10\n",
      "\n",
      "Error:j.\n",
      "Candidates: ['j', 'joy', 'job', 'go', 'jug', 'to', 'he', 'jew', 'do', 'jem']\n",
      "Correction: j\n",
      "mr j. was very angray -> mr j was very angray\n",
      "hits = 10\n",
      "\n",
      "Error:leavs\n",
      "Candidates: ['leaves', 'laws', 'leave', 'leads', 'lads', 'leaps', 'loans', 'means', 'learns', 'lead']\n",
      "Correction: leaves\n",
      "garden full of leavs -> garden full of leaves\n",
      "hits = 11\n",
      "\n",
      "Error:manger\n",
      "Candidates: ['manager', 'managers', 'danger', 'managed', 'manger', 'manage', 'finger', 'dangers', 'monger', 'matter']\n",
      "Correction: manger\n",
      "talk to the manger -> talk to the manger\n",
      "hits = 11\n",
      "\n",
      "Error:aero\n",
      "Candidates: ['area', 'are', 'were', 'air', 'her', 'aaron', 'hero', 'here', 'apron', 'also']\n",
      "Correction: hero\n",
      "they throw a aero -> they throw a hero\n",
      "hits = 11\n",
      "\n",
      "Error:ansion\n",
      "Candidates: ['union', 'action', 'unison', 'onion', 'ention', 'anon', 'arson', 'ensign', 'anton', 'angio']\n",
      "Correction: action\n",
      "an ansion method of hunting -> an action method of hunting\n",
      "hits = 11\n",
      "\n",
      "Precision: 0.55\n",
      "FalseAlarm: 0.45\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "arm = 0\n",
    "for i,line in enumerate (test_False):\n",
    "    word = line.split(' ')\n",
    "    detect_sentence = detect_where(word)\n",
    "    start = detect_sentence[0]\n",
    "    combine ,wrong ,right ,candidate ,_ =find_the_best(word,start)\n",
    "    combine = ' '.join(combine).strip()\n",
    "    if combine == test_Correct[i]:\n",
    "        hits+=1\n",
    "    arm += 1\n",
    "    \n",
    "    f = open('lab4_106065503.txt','a')\n",
    "    \n",
    "    print(\"Error:\" +  str(wrong))\n",
    "    f.write(\"Error:\" +  str(wrong)+'\\n')\n",
    "    \n",
    "    print(\"Candidates:\", candidate)\n",
    "    f.write(\"Candidates:\" +  str(candidate)+'\\n')\n",
    "    \n",
    "    print(\"Correction:\", right)\n",
    "    f.write(\"Correction:\" +  str(right)+'\\n')\n",
    "    \n",
    "    print(test_False[i], \"->\", combine )\n",
    "    f.write(test_False[i] + \"->\" + combine+'\\n')\n",
    "    \n",
    "    print(\"hits =\", hits)\n",
    "    f.write(\"hits =\"+ str(hits)+'\\n\\n')\n",
    "    \n",
    "    print()\n",
    "    \n",
    "f = open('lab4_106065503.txt','a')\n",
    "\n",
    "print(\"Precision:\", hits/arm)\n",
    "f.write(\"Precision:\"+ str(hits/arm)+'\\n')\n",
    "\n",
    "print(\"FalseAlarm:\", (arm-hits)/arm)\n",
    "f.write(\"FalseAlarm:\"+str((arm-hits)/arm)+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
